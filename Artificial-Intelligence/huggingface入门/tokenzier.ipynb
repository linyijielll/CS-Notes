{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hugging_face_01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel"
      ],
      "metadata": {
        "id": "XlLmuTowr0R1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained('bert-base-cased')\n",
        "model.save_pretrained('./download/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMV-ZQx0r0YV",
        "outputId": "ef48648d-3a58-4ec2-92fb-9d96c1c1f2ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "s = 'today is a good day to learn transformers'\n",
        "tokenizer(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJmg0T9Dr0at",
        "outputId": "416d45c6-560d-491b-bb3b-0f0bc8ed189e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2052, 1110, 170, 1363, 1285, 1106, 3858, 11303, 1468, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "了解tokenizer内部具体步骤"
      ],
      "metadata": {
        "id": "Kk37Je2ByOao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize()\n",
        "s = 'today is a good day to learn transformers'\n",
        "tokens = tokenizer.tokenize(s)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kc7p8M3r0dD",
        "outputId": "057ce550-0452-4b84-b2bd-26dd16a73558"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['today', 'is', 'a', 'good', 'day', 'to', 'learn', 'transform', '##ers']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert_token_to_ids()\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSER5D2Ar0fY",
        "outputId": "4a833d77-a9f7-4fa0-86a0-320054467d05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2052, 1110, 170, 1363, 1285, 1106, 3858, 11303, 1468]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decode\n",
        "# 会把 ## 自动拼起来\n",
        "print(tokenizer.decode([11303,1468]))\n",
        "print(tokenizer.decode(ids)) \n",
        "print(tokenizer.decode([101, 2052, 1110, 170, 1363, 1285, 1106, 3858, 11303, 1468, 102]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZfxh7Unr0hx",
        "outputId": "ea6037bd-4ee0-4b7f-8568-72aa37a4aa64"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers\n",
            "today is a good day to learn transformers\n",
            "[CLS] today is a good day to learn transformers [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "attention_mask 在处理多个序列时的作用"
      ],
      "metadata": {
        "id": "zs3avWbAz7AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint as print  # 这个pprint能让打印的格式更好看一点\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "jWFcexKIr0kZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "处理单个文本"
      ],
      "metadata": {
        "id": "rAMNq0-42lvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 'Today is a nice day!'\n",
        "inputs = tokenizer(s,return_tensors='pt')\n",
        "print(tokenizer.decode([ 101, 3570, 1110,  170, 3505, 1285,  106,  102]))\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8yAoq1vr0mz",
        "outputId": "8e2cabdd-e28a-4b9f-b746-489d3a3fec54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'[CLS] status ɑ [unused165] mike ض [unused101] [SEP]'\n",
            "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]]),\n",
            " 'input_ids': tensor([[ 101, 2651, 2003, 1037, 3835, 2154,  999,  102]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(inputs.input_ids).logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oejub5Jsr0p1",
        "outputId": "cc022814-c4eb-4b1d-a572-c92c78137f9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.3232,  4.6906]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "处理多个文本"
      ],
      "metadata": {
        "id": "6L_dGllY3xSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss = ['Today is a nice day!',\n",
        "      'But what about tomorrow? Im not sure.']\n",
        "inputs = tokenizer(ss, padding=True, return_tensors='pt')\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSTRFDIOr0sQ",
        "outputId": "17ecd2e7-02d3-4f34-d670-5797cf2d7f37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
            " 'input_ids': tensor([[  101,  2651,  2003,  1037,  3835,  2154,   999,   102,     0,     0,\n",
            "             0],\n",
            "        [  101,  2021,  2054,  2055,  4826,  1029, 10047,  2025,  2469,  1012,\n",
            "           102]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(inputs.input_ids).logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQEBBQyNr0u-",
        "outputId": "2b7877e4-4d0e-42ac-e7b7-8afa782cd337"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.1957,  4.5675],\n",
              "        [ 3.9803, -3.2120]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "因为在padding之后，第一个句子的encoding变了，多了很多0， 而self-attention会attend到所有的index的值，因此结果就变了。这时，就需要我们不仅仅是传入input_ids，还需要给出attention_mask，这样模型就会在attention的时候，不去attend被mask掉的部。"
      ],
      "metadata": {
        "id": "PmCipcUp5GHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(inputs.input_ids,inputs.attention_mask).logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rad7A7wb5Jld",
        "outputId": "ebf8ae1e-bd41-46bb-ad1b-d5719be4babb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.3232,  4.6906],\n",
              "        [ 3.9803, -3.2120]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = model.config.id2label"
      ],
      "metadata": {
        "id": "WKZr0kPm62-P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "predictions = torch.nn.functional.softmax(model(inputs.input_ids,inputs.attention_mask).logits, dim=-1)  \n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBH-ppZP5JoV",
        "outputId": "bae5e8c2-30de-4011-9218-f502bf2a3b60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2170e-04, 9.9988e-01],\n",
              "        [9.9925e-01, 7.5180e-04]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in torch.argmax(predictions, dim=-1):\n",
        "    print(id2label[i.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxxB_MRx5JrX",
        "outputId": "e1aca260-1755-4e2e-efbb-a310b343852c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'POSITIVE'\n",
            "'NEGATIVE'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YdMX88WZ5Jxf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ji6u1HGB5J0I"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}